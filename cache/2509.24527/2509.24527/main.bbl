\begin{thebibliography}{84}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Hafner et~al.(2025)Hafner, Pasukonis, Ba, and Lillicrap]{dreamerv3}
Danijar Hafner, Jurgis Pasukonis, Jimmy Ba, and Timothy Lillicrap.
\newblock Mastering diverse control tasks through world models.
\newblock \emph{Nature}, pages 1--7, 2025.

\bibitem[Wu et~al.(2023)Wu, Escontrela, Hafner, Abbeel, and
  Goldberg]{wu2023daydreamer}
Philipp Wu, Alejandro Escontrela, Danijar Hafner, Pieter Abbeel, and Ken
  Goldberg.
\newblock Daydreamer: World models for physical robot learning.
\newblock In \emph{Conference on robot learning}, pages 2226--2240. PMLR, 2023.

\bibitem[Hansen et~al.(2023)Hansen, Su, and Wang]{hansen2023tdtmpc2}
Nicklas Hansen, Hao Su, and Xiaolong Wang.
\newblock Td-mpc2: Scalable, robust world models for continuous control.
\newblock \emph{arXiv preprint arXiv:2310.16828}, 2023.

\bibitem[Alonso et~al.(2024)Alonso, Jelley, Micheli, Kanervisto, Storkey,
  Pearce, and Fleuret]{alonso2024diffusion}
Eloi Alonso, Adam Jelley, Vincent Micheli, Anssi Kanervisto, Amos~J Storkey,
  Tim Pearce, and Fran{\c{c}}ois Fleuret.
\newblock Diffusion for world modeling: Visual details matter in atari.
\newblock \emph{Advances in Neural Information Processing Systems},
  37:\penalty0 58757--58791, 2024.

\bibitem[Schrittwieser et~al.(2019)Schrittwieser, Antonoglou, Hubert, Simonyan,
  Sifre, Schmitt, Guez, Lockhart, Hassabis, Graepel,
  et~al.]{schrittwieser2019muzero}
Julian Schrittwieser, Ioannis Antonoglou, Thomas Hubert, Karen Simonyan,
  Laurent Sifre, Simon Schmitt, Arthur Guez, Edward Lockhart, Demis Hassabis,
  Thore Graepel, et~al.
\newblock Mastering atari, go, chess and shogi by planning with a learned
  model.
\newblock \emph{arXiv preprint arXiv:1911.08265}, 2019.

\bibitem[Hessel et~al.(2021)Hessel, Danihelka, Viola, Guez, Schmitt, Sifre,
  Weber, Silver, and Van~Hasselt]{hessel2021muesli}
Matteo Hessel, Ivo Danihelka, Fabio Viola, Arthur Guez, Simon Schmitt, Laurent
  Sifre, Theophane Weber, David Silver, and Hado Van~Hasselt.
\newblock Muesli: Combining improvements in policy optimization.
\newblock In \emph{International Conference on Machine Learning}, pages
  4214--4226. PMLR, 2021.

\bibitem[Ball et~al.(2025)Ball, Bauer, Belletti, Brownfield, Ephrat, Fruchter,
  Gupta, Holsheimer, Holynski, Hron, Kaplanis, Limont, McGill, Oliveira,
  Parker-Holder, Perbet, Scully, Shar, Spencer, Tov, Villegas, Wang, Yung,
  Baetu, Berbel, Bridson, Bruce, Buttimore, Chakera, Chandra, Collins, Cullum,
  Damoc, Dasagi, Gazeau, Gbadamosi, Han, Hirst, Kachra, Kerley, Kjems,
  Knoepfel, Koriakin, Lo, Lu, Mehring, Moufarek, Nandwani, Oliveira, Pardo,
  Park, Pierson, Poole, Ran, Salimans, Sanchez, Saprykin, Shen, Sidhwani,
  Smith, Stanton, Tomlinson, Vijaykumar, Wang, Wingfield, Wong, Xu, Yew, Young,
  Zubov, Eck, Erhan, Kavukcuoglu, Hassabis, Gharamani, Hadsell, van~den Oord,
  Mosseri, Bolton, Singh, and Rockt{\"a}schel]{genie3}
Philip~J. Ball, Jakob Bauer, Frank Belletti, Bethanie Brownfield, Ariel Ephrat,
  Shlomi Fruchter, Agrim Gupta, Kristian Holsheimer, Aleksander Holynski, Jiri
  Hron, Christos Kaplanis, Marjorie Limont, Matt McGill, Yanko Oliveira, Jack
  Parker-Holder, Frank Perbet, Guy Scully, Jeremy Shar, Stephen Spencer, Omer
  Tov, Ruben Villegas, Emma Wang, Jessica Yung, Cip Baetu, Jordi Berbel, David
  Bridson, Jake Bruce, Gavin Buttimore, Sarah Chakera, Bilva Chandra, Paul
  Collins, Alex Cullum, Bogdan Damoc, Vibha Dasagi, Maxime Gazeau, Charles
  Gbadamosi, Woohyun Han, Ed~Hirst, Ashyana Kachra, Lucie Kerley, Kristian
  Kjems, Eva Knoepfel, Vika Koriakin, Jessica Lo, Cong Lu, Zeb Mehring, Alex
  Moufarek, Henna Nandwani, Valeria Oliveira, Fabio Pardo, Jane Park, Andrew
  Pierson, Ben Poole, Helen Ran, Tim Salimans, Manuel Sanchez, Igor Saprykin,
  Amy Shen, Sailesh Sidhwani, Duncan Smith, Joe Stanton, Hamish Tomlinson,
  Dimple Vijaykumar, Luyu Wang, Piers Wingfield, Nat Wong, Keyang Xu,
  Christopher Yew, Nick Young, Vadim Zubov, Douglas Eck, Dumitru Erhan, Koray
  Kavukcuoglu, Demis Hassabis, Zoubin Gharamani, Raia Hadsell, A{\"a}ron
  van~den Oord, Inbar Mosseri, Adrian Bolton, Satinder Singh, and Tim
  Rockt{\"a}schel.
\newblock Genie 3: A new frontier for world models.
\newblock
  \url{https://deepmind.google/discover/blog/genie-3-a-new-frontier-for-world-models/},
  2025.

\bibitem[Tu et~al.(2025)Tu, Luo, Chen, Bai, Wang, and Zhao]{tu2025playerone}
Yuanpeng Tu, Hao Luo, Xi~Chen, Xiang Bai, Fan Wang, and Hengshuang Zhao.
\newblock Playerone: Egocentric world simulator.
\newblock \emph{arXiv preprint arXiv:2506.09995}, 2025.

\bibitem[He et~al.(2025)He, Peng, Liu, Wang, Zhang, Cui, Kang, Jiang, An, Ren,
  et~al.]{he2025matrix}
Xianglong He, Chunli Peng, Zexiang Liu, Boyang Wang, Yifan Zhang, Qi~Cui, Fei
  Kang, Biao Jiang, Mengyin An, Yangyang Ren, et~al.
\newblock Matrix-game 2.0: An open-source, real-time, and streaming interactive
  world model.
\newblock \emph{arXiv preprint arXiv:2508.13009}, 2025.

\bibitem[Sun et~al.(2025)Sun, Wei, Zhao, Chen, Chen, Zhang, Zhang, and
  Lu]{sun2025virtual}
Wenqiang Sun, Fangyun Wei, Jinjing Zhao, Xi~Chen, Zilong Chen, Hongyang Zhang,
  Jun Zhang, and Yan Lu.
\newblock From virtual games to real-world play.
\newblock \emph{arXiv preprint arXiv:2506.18901}, 2025.

\bibitem[Bai et~al.(2025)Bai, Tran, Bar, LeCun, Darrell, and
  Malik]{bai2025whole}
Yutong Bai, Danny Tran, Amir Bar, Yann LeCun, Trevor Darrell, and Jitendra
  Malik.
\newblock Whole-body conditioned egocentric video prediction.
\newblock \emph{arXiv preprint arXiv:2506.21552}, 2025.

\bibitem[Team(2025)]{team2025yan}
Yan Team.
\newblock Yan: Foundational interactive video generation.
\newblock \emph{arXiv preprint arXiv:2508.08601}, 2025.

\bibitem[Peebles and Xie(2023)]{peebles2023dit}
William Peebles and Saining Xie.
\newblock Scalable diffusion models with transformers.
\newblock In \emph{Proceedings of the IEEE/CVF international conference on
  computer vision}, pages 4195--4205, 2023.

\bibitem[Chen et~al.(2024)Chen, Mart{\'\i}~Mons{\'o}, Du, Simchowitz, Tedrake,
  and Sitzmann]{diffusionforcing}
Boyuan Chen, Diego Mart{\'\i}~Mons{\'o}, Yilun Du, Max Simchowitz, Russ
  Tedrake, and Vincent Sitzmann.
\newblock Diffusion forcing: Next-token prediction meets full-sequence
  diffusion.
\newblock \emph{Advances in Neural Information Processing Systems},
  37:\penalty0 24081--24125, 2024.

\bibitem[Baker et~al.(2022)Baker, Akkaya, Zhokov, Huizinga, Tang, Ecoffet,
  Houghton, Sampedro, and Clune]{vpt}
Bowen Baker, Ilge Akkaya, Peter Zhokov, Joost Huizinga, Jie Tang, Adrien
  Ecoffet, Brandon Houghton, Raul Sampedro, and Jeff Clune.
\newblock Video pretraining (vpt): Learning to act by watching unlabeled online
  videos.
\newblock \emph{Advances in Neural Information Processing Systems},
  35:\penalty0 24639--24654, 2022.

\bibitem[Sohl-Dickstein et~al.(2015)Sohl-Dickstein, Weiss, Maheswaranathan, and
  Ganguli]{sohl2015deep}
Jascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan, and Surya Ganguli.
\newblock Deep unsupervised learning using nonequilibrium thermodynamics.
\newblock In \emph{International conference on machine learning}, pages
  2256--2265. pmlr, 2015.

\bibitem[Ho et~al.(2020)Ho, Jain, and Abbeel]{ddpm}
Jonathan Ho, Ajay Jain, and Pieter Abbeel.
\newblock Denoising diffusion probabilistic models.
\newblock \emph{Advances in neural information processing systems},
  33:\penalty0 6840--6851, 2020.

\bibitem[Lipman et~al.(2022)Lipman, Chen, Ben-Hamu, Nickel, and
  Le]{flowmatching}
Yaron Lipman, Ricky~TQ Chen, Heli Ben-Hamu, Maximilian Nickel, and Matt Le.
\newblock Flow matching for generative modeling.
\newblock \emph{arXiv preprint arXiv:2210.02747}, 2022.

\bibitem[Liu et~al.(2022)Liu, Gong, and Liu]{rectifiedflow}
Xingchao Liu, Chengyue Gong, and Qiang Liu.
\newblock Flow straight and fast: Learning to generate and transfer data with
  rectified flow.
\newblock \emph{arXiv preprint arXiv:2209.03003}, 2022.

\bibitem[Esser et~al.(2024)Esser, Kulal, Blattmann, Entezari, M{\"u}ller,
  Saini, Levi, Lorenz, Sauer, Boesel, et~al.]{sd3}
Patrick Esser, Sumith Kulal, Andreas Blattmann, Rahim Entezari, Jonas
  M{\"u}ller, Harry Saini, Yam Levi, Dominik Lorenz, Axel Sauer, Frederic
  Boesel, et~al.
\newblock Scaling rectified flow transformers for high-resolution image
  synthesis.
\newblock In \emph{Forty-first international conference on machine learning},
  2024.

\bibitem[Frans et~al.(2024)Frans, Hafner, Levine, and Abbeel]{shortcut}
Kevin Frans, Danijar Hafner, Sergey Levine, and Pieter Abbeel.
\newblock One step diffusion via shortcut models.
\newblock \emph{arXiv preprint arXiv:2410.12557}, 2024.

\bibitem[Zhang et~al.(2018)Zhang, Isola, Efros, Shechtman, and Wang]{lpips}
Richard Zhang, Phillip Isola, Alexei~A Efros, Eli Shechtman, and Oliver Wang.
\newblock The unreasonable effectiveness of deep features as a perceptual
  metric.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 586--595, 2018.

\bibitem[He et~al.(2022)He, Chen, Xie, Li, Doll{\'a}r, and Girshick]{mae}
Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Doll{\'a}r, and Ross
  Girshick.
\newblock Masked autoencoders are scalable vision learners.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision
  and pattern recognition}, pages 16000--16009, 2022.

\bibitem[Chen et~al.(2025)Chen, Han, Chen, Li, Wang, Wang, Wang, Liu, Zou, and
  Raj]{chen2025maetok}
Hao Chen, Yujin Han, Fangyi Chen, Xiang Li, Yidong Wang, Jindong Wang, Ze~Wang,
  Zicheng Liu, Difan Zou, and Bhiksha Raj.
\newblock Masked autoencoders are effective tokenizers for diffusion models.
\newblock In \emph{Forty-second International Conference on Machine Learning},
  2025.

\bibitem[Darcet et~al.(2023)Darcet, Oquab, Mairal, and Bojanowski]{vitregister}
Timoth{\'e}e Darcet, Maxime Oquab, Julien Mairal, and Piotr Bojanowski.
\newblock Vision transformers need registers.
\newblock \emph{arXiv preprint arXiv:2309.16588}, 2023.

\bibitem[Kingma and Gao(2023)]{kingma2023understanding}
Diederik Kingma and Ruiqi Gao.
\newblock Understanding diffusion objectives as the elbo with simple data
  augmentation.
\newblock \emph{Advances in Neural Information Processing Systems},
  36:\penalty0 65484--65516, 2023.

\bibitem[Gloeckle et~al.(2024)Gloeckle, Idrissi, Rozi{\`e}re, Lopez-Paz, and
  Synnaeve]{gloeckle2024mtp}
Fabian Gloeckle, Badr~Youbi Idrissi, Baptiste Rozi{\`e}re, David Lopez-Paz, and
  Gabriel Synnaeve.
\newblock Better \& faster large language models via multi-token prediction.
\newblock \emph{arXiv preprint arXiv:2404.19737}, 2024.

\bibitem[Sutton(1988)]{sutton1988td}
Richard~S Sutton.
\newblock Learning to predict by the methods of temporal differences.
\newblock \emph{Machine learning}, 3\penalty0 (1):\penalty0 9--44, 1988.

\bibitem[Abdolmaleki et~al.(2024)Abdolmaleki, Piot, Shahriari, Springenberg,
  Hertweck, Joshi, Oh, Bloesch, Lampe, Heess, et~al.]{abdolmaleki2024pmpo}
Abbas Abdolmaleki, Bilal Piot, Bobak Shahriari, Jost~Tobias Springenberg, Tim
  Hertweck, Rishabh Joshi, Junhyuk Oh, Michael Bloesch, Thomas Lampe, Nicolas
  Heess, et~al.
\newblock Preference optimization as probabilistic inference.
\newblock \emph{arXiv e-prints}, pages arXiv--2410, 2024.

\bibitem[Shannon(1948)]{shannon1948infotheory}
Claude~E Shannon.
\newblock A mathematical theory of communication.
\newblock \emph{Bell system technical journal}, 27\penalty0 (3):\penalty0
  379--423, 1948.

\bibitem[Vaswani(2017)]{vaswani2017transformer}
A~Vaswani.
\newblock Attention is all you need.
\newblock \emph{Advances in Neural Information Processing Systems}, 2017.

\bibitem[Zhang and Sennrich(2019)]{rmsnorm}
Biao Zhang and Rico Sennrich.
\newblock Root mean square layer normalization.
\newblock \emph{Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[Su et~al.(2021)Su, Zhang, Li, Zhang, and Li]{rope}
J~Su, H~Zhang, X~Li, J~Zhang, and Y~RoFormer Li.
\newblock Enhanced transformer with rotary position embedding.
\newblock In \emph{Proceedings of the 59th Annual Meeting of the Association
  for Computational Linguistics and the 11th International Joint Conference on
  Natural Language Processing (ACL-IJCNLP), Association for Computational
  Linguistics, Online}, pages 1--6, 2021.

\bibitem[Shazeer(2020)]{swiglu}
Noam Shazeer.
\newblock Glu variants improve transformer.
\newblock \emph{arXiv preprint arXiv:2002.05202}, 2020.

\bibitem[Dehghani et~al.(2023)Dehghani, Djolonga, Mustafa, Padlewski, Heek,
  Gilmer, Steiner, Caron, Geirhos, Alabdulmohsin, et~al.]{dehghani2023scaling}
Mostafa Dehghani, Josip Djolonga, Basil Mustafa, Piotr Padlewski, Jonathan
  Heek, Justin Gilmer, Andreas~Peter Steiner, Mathilde Caron, Robert Geirhos,
  Ibrahim Alabdulmohsin, et~al.
\newblock Scaling vision transformers to 22 billion parameters.
\newblock In \emph{International Conference on Machine Learning}, pages
  7480--7512. PMLR, 2023.

\bibitem[Bello et~al.(2016)Bello, Pham, Le, Norouzi, and
  Bengio]{bello2016neural}
Irwan Bello, Hieu Pham, Quoc~V Le, Mohammad Norouzi, and Samy Bengio.
\newblock Neural combinatorial optimization with reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1611.09940}, 2016.

\bibitem[Team et~al.(2024)Team, Riviere, Pathak, Sessa, Hardin, Bhupatiraju,
  Hussenot, Mesnard, Shahriari, Ram{\'e}, et~al.]{gemma2}
Gemma Team, Morgane Riviere, Shreya Pathak, Pier~Giuseppe Sessa, Cassidy
  Hardin, Surya Bhupatiraju, L{\'e}onard Hussenot, Thomas Mesnard, Bobak
  Shahriari, Alexandre Ram{\'e}, et~al.
\newblock Gemma 2: Improving open language models at a practical size.
\newblock \emph{arXiv preprint arXiv:2408.00118}, 2024.

\bibitem[Ho et~al.(2019)Ho, Kalchbrenner, Weissenborn, and Salimans]{axial}
Jonathan Ho, Nal Kalchbrenner, Dirk Weissenborn, and Tim Salimans.
\newblock Axial attention in multidimensional transformers.
\newblock \emph{arXiv preprint arXiv:1912.12180}, 2019.

\bibitem[Singh(2025)]{llama4}
Ajit Singh.
\newblock Meta llama 4: The future of multimodal ai.
\newblock \emph{Available at SSRN 5208228}, 2025.

\bibitem[Ainslie et~al.(2023)Ainslie, Lee-Thorp, De~Jong, Zemlyanskiy,
  Lebr{\'o}n, and Sanghai]{gqa}
Joshua Ainslie, James Lee-Thorp, Michiel De~Jong, Yury Zemlyanskiy, Federico
  Lebr{\'o}n, and Sumit Sanghai.
\newblock Gqa: Training generalized multi-query transformer models from
  multi-head checkpoints.
\newblock \emph{arXiv preprint arXiv:2305.13245}, 2023.

\bibitem[Kim et~al.(2024)Kim, Pertsch, Karamcheti, Xiao, Balakrishna, Nair,
  Rafailov, Foster, Lam, Sanketi, et~al.]{kim2024openvla}
Moo~Jin Kim, Karl Pertsch, Siddharth Karamcheti, Ted Xiao, Ashwin Balakrishna,
  Suraj Nair, Rafael Rafailov, Ethan Foster, Grace Lam, Pannag Sanketi, et~al.
\newblock Openvla: An open-source vision-language-action model.
\newblock \emph{arXiv preprint arXiv:2406.09246}, 2024.

\bibitem[Intelligence et~al.(2025)Intelligence, Black, Brown, Darpinian,
  Dhabalia, Driess, Esmail, Equi, Finn, Fusai, et~al.]{intelligence2025pi05}
Physical Intelligence, Kevin Black, Noah Brown, James Darpinian, Karan
  Dhabalia, Danny Driess, Adnan Esmail, Michael Equi, Chelsea Finn, Niccolo
  Fusai, et~al.
\newblock pi0.5: a vision-language-action model with open-world generalization.
\newblock \emph{arXiv preprint arXiv:2504.16054}, 2025.

\bibitem[Team et~al.(2025)Team, Kamath, Ferret, Pathak, Vieillard, Merhej,
  Perrin, Matejovicova, Ram{\'e}, Rivi{\`e}re, et~al.]{team2025gemma3}
Gemma Team, Aishwarya Kamath, Johan Ferret, Shreya Pathak, Nino Vieillard,
  Ramona Merhej, Sarah Perrin, Tatiana Matejovicova, Alexandre Ram{\'e},
  Morgane Rivi{\`e}re, et~al.
\newblock Gemma 3 technical report.
\newblock \emph{arXiv preprint arXiv:2503.19786}, 2025.

\bibitem[Zhao et~al.(2023)Zhao, Gu, Varma, Luo, Huang, Xu, Wright, Shojanazeri,
  Ott, Shleifer, et~al.]{fsdp}
Yanli Zhao, Andrew Gu, Rohan Varma, Liang Luo, Chien-Chin Huang, Min Xu, Less
  Wright, Hamid Shojanazeri, Myle Ott, Sam Shleifer, et~al.
\newblock Pytorch fsdp: experiences on scaling fully sharded data parallel.
\newblock \emph{arXiv preprint arXiv:2304.11277}, 2023.

\bibitem[Rasley et~al.(2020)Rasley, Rajbhandari, Ruwase, and He]{deepspeed}
Jeff Rasley, Samyam Rajbhandari, Olatunji Ruwase, and Yuxiong He.
\newblock Deepspeed: System optimizations enable training deep learning models
  with over 100 billion parameters.
\newblock In \emph{Proceedings of the 26th ACM SIGKDD international conference
  on knowledge discovery \& data mining}, pages 3505--3506, 2020.

\bibitem[Decart and Etched(2024)]{oasis}
Decart and Etched.
\newblock Oasis: A universe in a transformer.
\newblock https://www.decart.ai/articles/oasis-interactive-ai-video-game-model,
  2024.

\bibitem[Seid and Hojel(2024)]{lucidv1}
Rami Seid and Alberto Hojel.
\newblock Lucid v1: Real-tiem latent world models.
\newblock \emph{International Journal of Current Research in Science,
  Engineering \& Technology}, 2024.

\bibitem[Guo et~al.(2025)Guo, Ye, He, Wu, Jiang, Pearce, and Bian]{mineworld}
Junliang Guo, Yang Ye, Tianyu He, Haoyu Wu, Yushu Jiang, Tim Pearce, and Jiang
  Bian.
\newblock Mineworld: a real-time and open-source interactive world model on
  minecraft.
\newblock \emph{arXiv preprint arXiv:2504.08388}, 2025.

\bibitem[Zhou et~al.(2024{\natexlab{a}})Zhou, Atreya, Lee, Walke, Mees, and
  Levine]{soar}
Zhiyuan Zhou, Pranav Atreya, Abraham Lee, Homer Walke, Oier Mees, and Sergey
  Levine.
\newblock Autonomous improvement of instruction following skills via foundation
  models.
\newblock \emph{arXiv preprint arXiv:2407.20635}, 2024{\natexlab{a}}.

\bibitem[Unterthiner et~al.(2019)Unterthiner, Van~Steenkiste, Kurach, Marinier,
  Michalski, and Gelly]{fvd}
Thomas Unterthiner, Sjoerd Van~Steenkiste, Karol Kurach, Rapha{\"e}l Marinier,
  Marcin Michalski, and Sylvain Gelly.
\newblock Fvd: A new metric for video generation.
\newblock \emph{ICLR Workshop on Deep Generative Models for Highly Structured
  Data}, 2019.

\bibitem[Johnson et~al.(2016)Johnson, Hofmann, Hutton, and
  Bignell]{johnson2016malmo}
Matthew Johnson, Katja Hofmann, Tim Hutton, and David Bignell.
\newblock The malmo platform for artificial intelligence experimentation.
\newblock In \emph{IJCAI}, pages 4246--4247. Citeseer, 2016.

\bibitem[Guss et~al.(2019)Guss, Codel, Hofmann, Houghton, Kuno, Milani,
  Mohanty, Perez~Liebana, Salakhutdinov, Topin, et~al.]{guss2019minerl}
William~H Guss, Cayden Codel, Katja Hofmann, Brandon Houghton, Noboru Kuno,
  Stephanie Milani, Sharada Mohanty, Diego Perez~Liebana, Ruslan Salakhutdinov,
  Nicholay Topin, et~al.
\newblock The minerl competition on sample efficient reinforcement learning
  using human priors.
\newblock \emph{arXiv e-prints}, pages arXiv--1904, 2019.

\bibitem[Kanervisto et~al.(2022)Kanervisto, Milani, Ramanauskas, Topin, Lin,
  Li, Shi, Ye, Fu, Yang, et~al.]{kanervisto2022minerlcomp}
Anssi Kanervisto, Stephanie Milani, Karolis Ramanauskas, Nicholay Topin,
  Zichuan Lin, Junyou Li, Jianing Shi, Deheng Ye, Qiang Fu, Wei Yang, et~al.
\newblock Minerl diamond 2021 competition: Overview, results, and lessons
  learned.
\newblock \emph{NeurIPS 2021 Competitions and Demonstrations Track}, pages
  13--28, 2022.

\bibitem[Kanitscheider et~al.(2021)Kanitscheider, Huizinga, Farhi, Guss,
  Houghton, Sampedro, Zhokhov, Baker, Ecoffet, Tang,
  et~al.]{kanitscheider2021minecraftcurriculum}
Ingmar Kanitscheider, Joost Huizinga, David Farhi, William~Hebgen Guss, Brandon
  Houghton, Raul Sampedro, Peter Zhokhov, Bowen Baker, Adrien Ecoffet, Jie
  Tang, et~al.
\newblock Multi-task curriculum learning in a complex, visual, hard-exploration
  domain: Minecraft.
\newblock \emph{arXiv preprint arXiv:2106.14876}, 2021.

\bibitem[Lifshitz et~al.(2023)Lifshitz, Paster, Chan, Ba, and
  McIlraith]{lifshitz2023steve1}
Shalev Lifshitz, Keiran Paster, Harris Chan, Jimmy Ba, and Sheila McIlraith.
\newblock Steve-1: A generative model for text-to-behavior in minecraft.
\newblock \emph{Advances in Neural Information Processing Systems},
  36:\penalty0 69900--69929, 2023.

\bibitem[Cai et~al.(2023)Cai, Zhang, Wang, Ma, Liu, and
  Liang]{cai2023minecraftgroot}
Shaofei Cai, Bowei Zhang, Zihao Wang, Xiaojian Ma, Anji Liu, and Yitao Liang.
\newblock Groot: Learning to follow instructions by watching gameplay videos.
\newblock \emph{arXiv preprint arXiv:2310.08235}, 2023.

\bibitem[Zhou et~al.(2024{\natexlab{b}})Zhou, Qin, Yin, Huang, Zhang, Sheng,
  Qiao, and Shao]{zhou2024minedreamer}
Enshen Zhou, Yiran Qin, Zhenfei Yin, Yuzhou Huang, Ruimao Zhang, Lu~Sheng,
  Yu~Qiao, and Jing Shao.
\newblock Minedreamer: Learning to follow instructions via chain-of-imagination
  for simulated-world control.
\newblock \emph{arXiv preprint arXiv:2403.12037}, 2024{\natexlab{b}}.

\bibitem[Nieto et~al.(2021)Nieto, Creus, and Giro-i
  Nieto]{nieto2021minecraftskills}
Juan~Jos{\'e} Nieto, Roger Creus, and Xavier Giro-i Nieto.
\newblock Unsupervised skill-discovery and skill-learning in minecraft.
\newblock \emph{arXiv preprint arXiv:2107.08398}, 2021.

\bibitem[Sutton(1991)]{sutton1991dyna}
Richard~S Sutton.
\newblock Dyna, an integrated architecture for learning, planning, and
  reacting.
\newblock \emph{ACM SIGART Bulletin}, 2\penalty0 (4):\penalty0 160--163, 1991.

\bibitem[Deisenroth and Rasmussen(2011)]{deisenroth2011pilco}
Marc Deisenroth and Carl~E Rasmussen.
\newblock Pilco: A model-based and data-efficient approach to policy search.
\newblock In \emph{Proceedings of the 28th International Conference on machine
  learning (ICML-11)}, pages 465--472, 2011.

\bibitem[Watter et~al.(2015)Watter, Springenberg, Boedecker, and
  Riedmiller]{watter2015e2c}
Manuel Watter, Jost Springenberg, Joschka Boedecker, and Martin Riedmiller.
\newblock Embed to control: A locally linear latent dynamics model for control
  from raw images.
\newblock In \emph{Advances in neural information processing systems}, pages
  2746--2754, 2015.

\bibitem[Finn and Levine(2017)]{finn2017visualforesight}
Chelsea Finn and Sergey Levine.
\newblock Deep visual foresight for planning robot motion.
\newblock In \emph{2017 IEEE International Conference on Robotics and
  Automation (ICRA)}, pages 2786--2793. IEEE, 2017.

\bibitem[Ha and Schmidhuber(2018)]{ha2018worldmodels}
David Ha and J{\"u}rgen Schmidhuber.
\newblock World models.
\newblock \emph{arXiv preprint arXiv:1803.10122}, 2018.

\bibitem[Hafner et~al.(2018)Hafner, Lillicrap, Fischer, Villegas, Ha, Lee, and
  Davidson]{hafner2018planet}
Danijar Hafner, Timothy Lillicrap, Ian Fischer, Ruben Villegas, David Ha,
  Honglak Lee, and James Davidson.
\newblock Learning latent dynamics for planning from pixels.
\newblock \emph{arXiv preprint arXiv:1811.04551}, 2018.

\bibitem[Hafner et~al.(2019)Hafner, Lillicrap, Ba, and
  Norouzi]{hafner2019dreamer}
Danijar Hafner, Timothy Lillicrap, Jimmy Ba, and Mohammad Norouzi.
\newblock Dream to control: Learning behaviors by latent imagination.
\newblock \emph{arXiv preprint arXiv:1912.01603}, 2019.

\bibitem[Hafner et~al.(2020)Hafner, Lillicrap, Norouzi, and
  Ba]{hafner2020dreamerv2}
Danijar Hafner, Timothy Lillicrap, Mohammad Norouzi, and Jimmy Ba.
\newblock Mastering atari with discrete world models.
\newblock \emph{arXiv preprint arXiv:2010.02193}, 2020.

\bibitem[Micheli et~al.(2022)Micheli, Alonso, and Fleuret]{micheli2022iris}
Vincent Micheli, Eloi Alonso, and Fran{\c{c}}ois Fleuret.
\newblock Transformers are sample efficient world models.
\newblock \emph{arXiv preprint arXiv:2209.00588}, 2022.

\bibitem[Robine et~al.(2023)Robine, H{\"o}ftmann, Uelwer, and
  Harmeling]{robine2023twm}
Jan Robine, Marc H{\"o}ftmann, Tobias Uelwer, and Stefan Harmeling.
\newblock Transformer-based world models are happy with 100k interactions.
\newblock \emph{arXiv preprint arXiv:2303.07109}, 2023.

\bibitem[Zhang et~al.(2023)Zhang, Wang, Sun, Yuan, and Huang]{storm}
Weipu Zhang, Gang Wang, Jian Sun, Yetian Yuan, and Gao Huang.
\newblock Storm: Efficient stochastic transformer based world models for
  reinforcement learning.
\newblock \emph{Advances in Neural Information Processing Systems},
  36:\penalty0 27147--27166, 2023.

\bibitem[Yu et~al.(2025)Yu, Qin, Che, Liu, Wang, Wan, Zhang, Gai, Chen, and
  Liu]{yu2025survey}
Jiwen Yu, Yiran Qin, Haoxuan Che, Quande Liu, Xintao Wang, Pengfei Wan,
  Di~Zhang, Kun Gai, Hao Chen, and Xihui Liu.
\newblock A survey of interactive generative video.
\newblock \emph{arXiv preprint arXiv:2504.21853}, 2025.

\bibitem[Valevski et~al.(2024)Valevski, Leviathan, Arar, and
  Fruchter]{valevski2024diffusion}
Dani Valevski, Yaniv Leviathan, Moab Arar, and Shlomi Fruchter.
\newblock Diffusion models are real-time game engines.
\newblock \emph{arXiv preprint arXiv:2408.14837}, 2024.

\bibitem[Hu et~al.(2023)Hu, Russell, Yeo, Murez, Fedoseev, Kendall, Shotton,
  and Corrado]{hu2023gaia}
Anthony Hu, Lloyd Russell, Hudson Yeo, Zak Murez, George Fedoseev, Alex
  Kendall, Jamie Shotton, and Gianluca Corrado.
\newblock Gaia-1: A generative world model for autonomous driving.
\newblock \emph{arXiv preprint arXiv:2309.17080}, 2023.

\bibitem[Russell et~al.(2025)Russell, Hu, Bertoni, Fedoseev, Shotton, Arani,
  and Corrado]{russell2025gaia}
Lloyd Russell, Anthony Hu, Lorenzo Bertoni, George Fedoseev, Jamie Shotton,
  Elahe Arani, and Gianluca Corrado.
\newblock Gaia-2: A controllable multi-view generative world model for
  autonomous driving.
\newblock \emph{arXiv preprint arXiv:2503.20523}, 2025.

\bibitem[Chang et~al.(2022)Chang, Zhang, Jiang, Liu, and
  Freeman]{chang2022maskgit}
Huiwen Chang, Han Zhang, Lu~Jiang, Ce~Liu, and William~T Freeman.
\newblock Maskgit: Masked generative image transformer.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision
  and pattern recognition}, pages 11315--11325, 2022.

\bibitem[Salimans and Ho(2022)]{salimans2022progressive}
Tim Salimans and Jonathan Ho.
\newblock Progressive distillation for fast sampling of diffusion models.
\newblock \emph{arXiv preprint arXiv:2202.00512}, 2022.

\bibitem[Kodaira et~al.(2025)Kodaira, Hou, Hou, Tomizuka, and
  Zhao]{kodaira2025streamdit}
Akio Kodaira, Tingbo Hou, Ji~Hou, Masayoshi Tomizuka, and Yue Zhao.
\newblock Streamdit: Real-time streaming text-to-video generation.
\newblock \emph{arXiv preprint arXiv:2507.03745}, 2025.

\bibitem[Song et~al.(2023)Song, Dhariwal, Chen, and
  Sutskever]{song2023consistency}
Yang Song, Prafulla Dhariwal, Mark Chen, and Ilya Sutskever.
\newblock Consistency models.
\newblock \emph{International Conference on Machine Learning}, 2023.

\bibitem[Song and Dhariwal(2023)]{song2023improved}
Yang Song and Prafulla Dhariwal.
\newblock Improved techniques for training consistency models.
\newblock \emph{arXiv preprint arXiv:2310.14189}, 2023.

\bibitem[Lu and Song(2024)]{lu2024simplifying}
Cheng Lu and Yang Song.
\newblock Simplifying, stabilizing and scaling continuous-time consistency
  models.
\newblock \emph{arXiv preprint arXiv:2410.11081}, 2024.

\bibitem[Wang et~al.(2023)Wang, Zhang, Zhang, Liu, Zhang, Gao, and
  Sang]{wang2023videolcm}
Xiang Wang, Shiwei Zhang, Han Zhang, Yu~Liu, Yingya Zhang, Changxin Gao, and
  Nong Sang.
\newblock Videolcm: Video latent consistency model.
\newblock \emph{arXiv preprint arXiv:2312.09109}, 2023.

\bibitem[Geng et~al.(2025)Geng, Deng, Bai, Kolter, and He]{geng2025meanflow}
Zhengyang Geng, Mingyang Deng, Xingjian Bai, J~Zico Kolter, and Kaiming He.
\newblock Mean flows for one-step generative modeling.
\newblock \emph{arXiv preprint arXiv:2505.13447}, 2025.

\bibitem[Zhao et~al.(2024)Zhao, Jin, Wang, and You]{zhao2024real}
Xuanlei Zhao, Xiaolong Jin, Kai Wang, and Yang You.
\newblock Real-time video generation with pyramid attention broadcast.
\newblock \emph{arXiv preprint arXiv:2408.12588}, 2024.

\bibitem[Zhang et~al.(2025)Zhang, Chen, Huang, Lin, Liu, Stoica, Xing, and
  Zhang]{zhang2025vsa}
Peiyuan Zhang, Yongqi Chen, Haofeng Huang, Will Lin, Zhengzhong Liu, Ion
  Stoica, Eric Xing, and Hao Zhang.
\newblock Vsa: Faster video diffusion with trainable sparse attention.
\newblock \emph{arXiv preprint arXiv:2505.13389}, 2025.

\bibitem[Damen et~al.(2018)Damen, Doughty, Farinella, Fidler, Furnari, Kazakos,
  Moltisanti, Munro, Perrett, Price, et~al.]{epickitchens}
Dima Damen, Hazel Doughty, Giovanni~Maria Farinella, Sanja Fidler, Antonino
  Furnari, Evangelos Kazakos, Davide Moltisanti, Jonathan Munro, Toby Perrett,
  Will Price, et~al.
\newblock Scaling egocentric vision: The epic-kitchens dataset.
\newblock In \emph{Proceedings of the European conference on computer vision
  (ECCV)}, pages 720--736, 2018.

\end{thebibliography}
